[{"title":"3231note","date":"2023-04-25T14:32:58.000Z","url":"/2023/04/26/3231note/","tags":[["COMP3231","/tags/COMP3231/"]],"categories":[["notes","/categories/notes/"]],"content":"UNSW COMP3231 23T1 notes Lec 02 Processes and ThreadsProcesses:â€¢ Also called a task or job â€¢ Memory image of an individual program â€¢ â€œOwnerâ€ of resources allocated for program execution â€¢ Encompasses one or more threads Threads:â€¢ Unit of execution æ‰§è¡Œå‘½ä»¤çš„å•ä½ â€¢ Can be traced â€¢ list the sequence of instructions that execute â€¢ Belongs to a process â€¢ Executes within it. One Process may contain one or more threads. Process TerminationConditions which terminate processes 1. Normal exit (voluntary) 2. Error exit (voluntary) 3. Fatal error (involuntary) 4. Killed by another process (involuntary) Process and Thread StatesRunning Blocked Ready Running â†’ Readyâ€¢ Voluntary Yield() â€¢ End of timeslice Running â†’ Blockedâ€¢ Waiting for input â€¢ File, network, â€¢ Waiting for a timer (alarm signal) â€¢ Waiting for a resource to become available SchedularSometime called as dispatcher, it will choose a ready process to run. BUT: It is inefficient to search through all processes e.g: Ready Queue &amp; Blocked Queue Thread Model Per process items Per thread items Address spaceGlobal variablesOpen filesChild processesPending alarmsSignals and signal handlersAccounting information Program counterRegistersStack (Each thread has its own stack)State Local variables are per thread (allocated on the stack) Global variables are shared between all threads (Allocated in the data section) Concurrency control is an issue. Dynamically allocated memory can be global or local -&gt; Program defined Thread Usage Model æ¨¡å‹ Characteristics ç‰¹æ€§ Threads Parallelism. Blocking system calls Single-threaded Process No parallelism, blocking system calls Finite-state Machine Parallelism, nonblocking system calls, interrupts Summary in Threads Simpler to program than a state machine Less resources associated with threads than multiple complete processes Cheaper to create and destroy Share resources (especially memory) between them Performance: Threads waiting for IO can be overlapped with computing threads If all threads are compute bound(è¢«è¿ç®—é€Ÿåº¦é™åˆ¶), then there is no performance improvement (on uniprocessor) Threads can take advantage of the parallelism available on machines with more than one CPU (multiprocessor) Lec 03 Concurrency and SynchronisationConcurrency Example:Trying to modify a global variable in two threads The reason for why there is in-kernel concurrency for single-threaded processes: Multi-tasking Interrupt handling Device drivers System calls Resource sharing Critical Region and how to identifyA critical region is a region of code where shared resources are accessed. We can control access to the shared resource by controlling access to the code that accesses the resource. Uncoordinated entry to the critical region results in a race condition (Concurrency Occurs) HOW TO IDENTIFY: Critical regions are the regions of code that access a shared resource, and correctness relies on the shared resource not being concurrently modified by another thread&#x2F;process&#x2F;entity.\\ HOW TO PREVENT: Critical Regions SolutionsConditions required of any solution to the critical region problem: Mutual exclusion: No two processes&#x2F;threads in the critical region at the same time No assumptions made about speeds or numbers of CPUs No process running outside its critical region may block another process No process waited forever to enter its critical region (Bounded) Mutual exclusion by taking turnsWorks for solving concurrency issues: strict alternation -&gt; each process takes turns Cons (ç¼ºç‚¹) Busy waiting Process must wait its turn even while the other process is doing something else In a multiple processes condition, must wait for everyone to have a turn Does not guarantee progress if a process no longer needs a turn Poor solution when processes require the critical section at different rates Mutual Exclusion by disabling interruptsHow it works: Before entering a critical region, disable interrupts. After leaving the critical region, enable interrupts. Cons: Only available in the kernel Delays everybody else, even with no contention Slows the interrupt response time Does not work on a multiprocessor Hardware Support for mutual exclusionTest and Set instruction â€¢Can be used to implement lock variables correctly â€¢Load the value of the lock â€¢If lock &#x3D;&#x3D; 0 â€¢Set the lock to 1 â€¢Return the result 0 -&gt; we acquire the lock â€¢if lock &#x3D;&#x3D; 1 â€¢ return 1 -&gt; another thread&#x2F;process has the lock â€¢Hardware guarantees that the instruction executes atomically -&gt; not be interrupt Pros: Simple (easy to verify work or not) Available at user level Work with any number of processors To implement any number of lock variables Cons: Busy waits (also named as a spin lock) Consumes CPU Starvation is possible when a process leaves its critical section and more than one process is waiting. Tackling the busy-wait problem:Sleep&#x2F;Wakeup When the process is waiting for an event, it calls sleep to block, instead of busy waiting. The event happens, the event generator (another process) calls wakeup to unblock the sleeping process. Waking a ready&#x2F;running process has no effect. Producer-Consumer Problem(bounded buffer problem)Description: producer produces data items and store items in a buffer. Consumer takes the items out of the buffer and consumes them. Issues:Producer Should sleep when the buffer is full. And wakeup when there is empty space in the buffer. The consumer can call wakeup when it consumes the first entry of the full buffer. Consumer Should sleep when the buffer is empty. And wakeup when there are items available. Producer can call wakeup when it adds the first item to the buffer. SemaphoresTwo primitives that are more powerful than simple sleep and wakeup alone. â€¢ P(): proberen, from Dutch to test. â€¢ V(): verhogen, from Dutch to increment. â€¢ Also called wait &amp; signal, down &amp; up. How it works: If a resource is not available, the corresponding semaphore blocks any process waiting for the resource. Blocked processes are put into a process queue maintained by the semaphore (avoids busy waiting!) When a process releases a resource, it signals this by means of the semaphore. Signaling resumes a blocked process if there is any. Wait (P) and signal (V) operations cannot be interrupted. Complex coordination can be implemented by multiple semaphores. The initial count determines how many waits can progress before blocking and requiring a signal. Producer Consumer problem with semaphores: Summarising SemaphoresSemaphores can be used to solve a variety of concurrency problems. However, programming with then can be error-prone: E.g. must signal for every wait To many or too few signals or waits, or signals and waits in the wrong order, can have bad results. MonitorA higher level synchronisation primitive. Programming language construct IDEA: A set of procedures&#x2F;variables&#x2F;data types are grouped in a special module:monitor. Variables and data types can only be accessed from within the monitor. Only one process&#x2F;thread can be in the monitor at any one time. Mutual exclusion is implemented by the complier. When a thread calls a monitor procedure that has a thread already inside, it will be in the entry queue and will sleep until the current thread exits the monitor. Condition VariableTo allow a process to wait within the monitor, we need to declare a condition variable. Condition variable can only be used with the operations wait and signal. x.wait() Means that the process invoking this operation is suspended until another process invokes. Another thread can enter the monitor while original is suspended. x.signal() this operation resumes only one suspended process. If no process is suspended, then this operation has no effect. How to achieve producer-consumer problem with monitors is in P50 lec03. Synchronisation Primitives in OS&#x2F;161Locks Semaphores Wait (P) &#x2F; signal (V) Condition Variables Note: All three variants must hold the lock passed in. Condition Variables and Bounded Buffers cv_wait() will release the lock before block the process Producer-consumer solution with condition variable Dining Philosopherså“²å­¦å®¶å°±é¤é—®é¢˜æ˜¯ä¸€ä¸ªç»å…¸çš„è®¡ç®—æœºç§‘å­¦åŒæ­¥é—®é¢˜ï¼Œç”±Edsger Dijkstraåœ¨1965å¹´æå‡ºã€‚é—®é¢˜æè¿°äº†äº”ä½å“²å­¦å®¶å›´ååœ¨åœ†æ¡Œæ—çš„æƒ…æ™¯ï¼Œä»–ä»¬åœ¨æ€è€ƒé—®é¢˜å’Œåƒé¥­ä¹‹é—´äº¤æ›¿ã€‚åœ†æ¡Œä¸­é—´æœ‰ä¸€ç¢—æ„é¢ï¼Œæ¯ä¸¤ä½å“²å­¦å®¶ä¹‹é—´æœ‰ä¸€æ ¹ç­·å­ã€‚æ¯ä½å“²å­¦å®¶éœ€è¦ä¸¤æ ¹ç­·å­æ‰èƒ½åƒé¥­ã€‚å“²å­¦å®¶ä»¬ä¸èƒ½äº¤è°ˆï¼Œåªèƒ½æ€è€ƒæˆ–åƒé¥­ã€‚ é—®é¢˜åœ¨äºè®¾è®¡ä¸€ä¸ªåè®®ï¼Œä½¿å¾—æ¯ä½å“²å­¦å®¶éƒ½èƒ½å¤Ÿåœ¨éœ€è¦æ—¶ä½¿ç”¨ä¸¤æ ¹ç­·å­åƒé¥­ï¼Œè€Œä¸ä¼šå‡ºç°æ­»é”ï¼ˆå³æ‰€æœ‰å“²å­¦å®¶éƒ½åœ¨ç­‰å¾…ç­·å­ï¼Œæ— æ³•ç»§ç»­åƒé¥­ï¼‰æˆ–è€…é¥¥é¥¿ï¼ˆå³æŸä½å“²å­¦å®¶é•¿æ—¶é—´æ— æ³•è·å¾—ç­·å­ï¼‰çš„æƒ…å†µã€‚ ä»¥ä¸‹æ˜¯ä¸€ä¸ªå¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š æˆ‘ä»¬å¯ä»¥ä¸ºæ¯æ ¹ç­·å­åˆ†é…ä¸€ä¸ªç¼–å·ï¼ˆä¾‹å¦‚ï¼Œ1åˆ°5ï¼‰ï¼Œå¹¶ä¸ºæ¯ä½å“²å­¦å®¶åˆ†é…ä¸€ä¸ªç¼–å·ã€‚æ¯ä½å“²å­¦å®¶åœ¨éœ€è¦åƒé¥­æ—¶ï¼Œå…ˆå°è¯•æ‹¿èµ·ç¼–å·è¾ƒä½çš„ç­·å­ï¼Œç„¶åå°è¯•æ‹¿èµ·ç¼–å·è¾ƒé«˜çš„ç­·å­ã€‚å½“å“²å­¦å®¶åŒæ—¶æ‹¥æœ‰ä¸¤æ ¹ç­·å­æ—¶ï¼Œä»–ä»¬å¯ä»¥å¼€å§‹åƒé¥­ã€‚åƒå®Œé¥­åï¼Œä»–ä»¬å°†ç­·å­æ”¾å›åŸä½ï¼Œç„¶åç»§ç»­æ€è€ƒã€‚ è¿™ç§æ–¹æ³•å¯ä»¥é¿å…æ­»é”ï¼Œå› ä¸ºè‡³å°‘æœ‰ä¸€ä½å“²å­¦å®¶ï¼ˆå…·æœ‰æœ€ä½ç¼–å·ç­·å­çš„å“²å­¦å®¶ï¼‰å¯ä»¥æ‹¿èµ·ä¸¤æ ¹ç­·å­å¹¶å¼€å§‹åƒé¥­ã€‚å…¶ä»–å“²å­¦å®¶åˆ™éœ€è¦ç­‰å¾…ç­·å­è¢«æ”¾å›ã€‚è™½ç„¶è¿™ç§æ–¹æ³•å¯èƒ½å¯¼è‡´æŸäº›å“²å­¦å®¶ç­‰å¾…æ—¶é—´è¾ƒé•¿ï¼Œä½†å¯ä»¥ç¡®ä¿æ‰€æœ‰å“²å­¦å®¶éƒ½æœ‰æœºä¼šåƒé¥­ï¼Œé¿å…é¥¥é¥¿ç°è±¡ã€‚ Reader and Writer Problemè¯»è€…-å†™è€…é—®é¢˜æ˜¯ä¸€ä¸ªç»å…¸çš„è®¡ç®—æœºç§‘å­¦å¹¶å‘æ§åˆ¶é—®é¢˜ï¼Œç”¨äºæè¿°å¤šä¸ªè¿›ç¨‹åœ¨è®¿é—®å…±äº«èµ„æºæ—¶éœ€è¦è¿›è¡ŒåŒæ­¥çš„åœºæ™¯ã€‚åœ¨è¿™ä¸ªé—®é¢˜ä¸­ï¼Œæœ‰ä¸€äº›è¯»è€…è¿›ç¨‹å’Œå†™è€…è¿›ç¨‹ã€‚è¯»è€…è¿›ç¨‹åªè¯»å–å…±äº«èµ„æºï¼Œè€Œå†™è€…è¿›ç¨‹å¯ä»¥ä¿®æ”¹å…±äº«èµ„æºã€‚é—®é¢˜çš„æŒ‘æˆ˜åœ¨äºè®¾è®¡ä¸€ä¸ªåŒæ­¥åè®®ï¼Œä»¥å…è®¸å¤šä¸ªè¯»è€…è¿›ç¨‹åŒæ—¶è®¿é—®å…±äº«èµ„æºï¼Œä½†åœ¨å†™è€…è¿›ç¨‹è®¿é—®èµ„æºæ—¶ï¼Œç¡®ä¿å…¶ä»–è¿›ç¨‹ï¼ˆè¯»è€…å’Œå†™è€…ï¼‰æ— æ³•è®¿é—®èµ„æºã€‚ ä»¥ä¸‹æ˜¯ä¸€ä¸ªå¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š æˆ‘ä»¬å¯ä»¥ä½¿ç”¨äº’æ–¥é‡ï¼ˆmutexï¼‰å’Œä¿¡å·é‡ï¼ˆsemaphoreï¼‰æ¥å®ç°è¿™ä¸ªåè®®ã€‚åœ¨è¿™ä¸ªè§£å†³æ–¹æ¡ˆä¸­ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªäº’æ–¥é‡æ¥ä¿æŠ¤å¯¹å…±äº«èµ„æºçš„è®¿é—®è®¡æ•°å™¨ï¼Œä»¥åŠä¸€ä¸ªä¿¡å·é‡æ¥æ§åˆ¶å¯¹å…±äº«èµ„æºçš„è®¿é—®ã€‚ è¯»è€…è¿›ç¨‹ï¼š è¯·æ±‚äº’æ–¥é‡ä»¥ä¿®æ”¹è®¿é—®è®¡æ•°å™¨ã€‚ å°†è®¿é—®è®¡æ•°å™¨åŠ 1ã€‚å¦‚æœè¿™æ˜¯ç¬¬ä¸€ä¸ªè¯»è€…è¿›ç¨‹ï¼Œè¯·æ±‚ä¿¡å·é‡ä»¥é˜»æ­¢å†™è€…è¿›ç¨‹è®¿é—®å…±äº«èµ„æºã€‚ é‡Šæ”¾äº’æ–¥é‡ã€‚ è®¿é—®å…±äº«èµ„æºã€‚ è¯·æ±‚äº’æ–¥é‡ä»¥ä¿®æ”¹è®¿é—®è®¡æ•°å™¨ã€‚ å°†è®¿é—®è®¡æ•°å™¨å‡1ã€‚å¦‚æœè¿™æ˜¯æœ€åä¸€ä¸ªè¯»è€…è¿›ç¨‹ï¼Œé‡Šæ”¾ä¿¡å·é‡ä»¥å…è®¸å†™è€…è¿›ç¨‹è®¿é—®å…±äº«èµ„æºã€‚ é‡Šæ”¾äº’æ–¥é‡ã€‚ å†™è€…è¿›ç¨‹ï¼š è¯·æ±‚ä¿¡å·é‡ä»¥é˜»æ­¢å…¶ä»–è¿›ç¨‹è®¿é—®å…±äº«èµ„æºã€‚ è®¿é—®å…±äº«èµ„æºã€‚ é‡Šæ”¾ä¿¡å·é‡ä»¥å…è®¸å…¶ä»–è¿›ç¨‹è®¿é—®å…±äº«èµ„æºã€‚ è¿™ä¸ªè§£å†³æ–¹æ¡ˆå…è®¸å¤šä¸ªè¯»è€…è¿›ç¨‹åŒæ—¶è®¿é—®å…±äº«èµ„æºï¼Œä½†å½“æœ‰å†™è€…è¿›ç¨‹éœ€è¦è®¿é—®èµ„æºæ—¶ï¼Œå®ƒä»¬å°†ç­‰å¾…æ‰€æœ‰å½“å‰çš„è¯»è€…è¿›ç¨‹å®Œæˆã€‚åŒæ ·ï¼Œåœ¨å†™è€…è¿›ç¨‹è®¿é—®å…±äº«èµ„æºæ—¶ï¼Œå…¶ä»–è¯»è€…å’Œå†™è€…è¿›ç¨‹å°†è¢«é˜»æ­¢ã€‚è¿™ç§æ–¹æ³•å¯ä»¥ç¡®ä¿åœ¨å†™è€…è¿›ç¨‹è®¿é—®èµ„æºæ—¶ï¼Œæ²¡æœ‰å…¶ä»–è¿›ç¨‹å¯ä»¥è®¿é—®å…±äº«èµ„æºã€‚ Lec04 DeadLockDeadLock &amp; ResourcesDeadlocks occurs when Processes are granted exclusive access to devices&#x2F;locks&#x2F;tables.. We refer to these entities generally as resources. Deadlock: definition A set of processes is deadlocked if each process in the set is waiting for an event that only another process in the set can cause. In the deadlock situation, no process can Run Release resources Be awakened Four conditions for deadlock Mutual exclusion condition Each resource assigned to 1 process or is available Hold and wait condition Process holding resources can request additional No preemption condition Previously granted resources cannot be forcibly taken away Circular wait condition Must be a circular chain of 2 or more processes Each is waiting for resource held by next member of the chain Deadlock avoidance Just ignore the problem altogether Prevention é¢„é˜² Negating on of the four necessary conditions Detection and recovery Dynamic avoidance Careful resource allocation Method 1: Ostrich AlgorithmPretend there is no problem Reasonable if Deadlocks occur very rarely Cost of prevention is high UNIX and Windows takes this approach for some of the more complex resource relationships they manage Itâ€™s a trade off between Convenience (engineering approach) Correctness (mathematical approach) Method 2: Deadlock preventionResource allocation rules prevent deadlock by prevent one of the four conditions required for deadlock from occurring: Mutual exclusion Hold and wait No preemption Circular Wait Attacking the Mutual Exclusion Condition (Not feasible)Not feasible in general Some devices&#x2F;resources are intrinsically(æœ¬è´¨ä¸Š) not sharable. Attacking the hold and wait condition (request resources initially)Require processes to request resources before starting A process never has to wait for what it needs Issues: May not know required resources at start of run Which means not always possible Also ties up resources other processes could be using Variations: Process must give up all resources if it would block holding a resource Then request all immediately need Prone(å€¾å‘äº) to livelock Attacking the No Preemption condition(æ— ä¼˜å…ˆæƒæ¡ä»¶)(take resources away)Not a viable option Attacking the circular wait condition (Order resources)Numerically ordered resources (Resources ordering is a common technique) Method 3: Detection and recoveryNeed a method to determine if a system is deadlocked. Assuming deadlocked is detected, we need a method of recovery to restore progress to the system. Strategy:Note the resource ownership and requests A cycle can be found within the graph, which denotes a deadlock Detection with Multiple Resources of Each Type Sum of current resource allocation + resources available &#x3D; resources that exist Algorithm Look for an unmarked process Pi, for which the i-th row of R is less than or equal to A. If found, add the i-th row of C to A, and mark Pi, then go back to step 1. If no such process exists, terminate. The remaining processes are deadlocked. Recovery from DeadlockRecovery through preemption â€¢ take a resource from some other process â€¢ depends on nature of the resource Recovery through rollback â€¢ checkpoint a process periodically â€¢ use this saved state â€¢ restart the process if it is found deadlocked â€¢ No guarantee is wonâ€™t deadlock again Recovery through killing processes â€¢ crudest but simplest way to break a deadlock â€¢ kill one of the processes in the deadlock cycle â€¢ the other processes get its resources â€¢ choose process that can be rerun from the beginning Method 4: Deadlock AvoidanceOnly enough information is available in advance, we can avoid a deadlock. Maximum number of each resource required Safe and Unsafe statesA state is safe if â€¢ The system is not deadlocked â€¢ There exists a scheduling order that results in every process running to completion, even if they all request their maximum resources immediately Unsafe states are not necessarily deadlocked â€¢ With a lucky sequence, all processes may complete â€¢ However, we cannot guarantee that they will complete (not deadlock) â€¢ Safe states guarantee we will eventually complete all processes â€¢Deadlock avoidance algorithm â€¢ Only grant requests that result in safe states LiveLockLivelocked processes are not blocked, change state regularly, but never make progress Bankers AlgorithmModelled on a Banker with Customers â€¢ The banker has a limited amount of money to loan customers â€¢ Limited number of resources â€¢ Each customer can borrow money up to the customerâ€™s credit limit â€¢ Maximum number of resources required Basic Idea â€¢ Keep the bank in a safe state â€¢ So all customers are happy even if they all request to borrow up to their credit limit at the same time. â€¢ Customers wishing to borrow such that the bank would enter an unsafe state must wait until somebody else repays their loan such that the the transaction becomes safe StarvationA process never receives the resource it is waiting for, despite the resource (repeatedly) becoming free, the resource is always allocated to another waiting process One Solution: First come, first server Lec05 Processes and Threads ImplementationMIPS RegistersUser-mode accessible registers â€¢ 32 general purpose registers â€¢ r0 hardwired to zero â€¢ r31 the link register for jump-and-link (JAL) instruction HI&#x2F;LO â€¢ 2 * 32-bits for multiply and divide PC â€¢ Not directly visible â€¢ Modified implicitly by jump and branch instructions Branching and JumpingBranching and jumping have a branch delay slot â€¢ The instruction following a branch or jump is always executed prior to destination of jump ProcessMemory allocationMinimally consist of three segments â€¢ Text â€¢ contains the code (instructions) â€¢ Data â€¢ Global variables â€¢ Stack â€¢ Activation records of procedure&#x2F;function&#x2F;method â€¢ Local variables Note: â€¢ data can dynamically grow up â€¢ E.g., malloc()-ing â€¢ The stack can dynamically grow down â€¢ E.g., increasing function call depth or recursion P23 lec05 Mode distinguishUser-mode â€¢ Processes (programs) scheduled by the kernel â€¢ Isolated from each other â€¢ No concurrency issues between each other System-calls transition into and return from the kernel Kernel-mode â€¢ Nearly all activities still associated with a process â€¢ Kernel memory shared between all processes â€¢ Concurrency issues exist between processes concurrently executing in a system call User-level Threads Implementation at user-level â€¢ User-level Thread Control Block (TCB), ready queue, blocked queue, and dispatcher â€¢ Kernel has no knowledge of the threads (it only sees a single process) â€¢ If a thread blocks waiting for a resource held by another thread inside the same process, its state is saved and the dispatcher switches to another ready thread â€¢ Thread management (create, exit, yield, wait) are implemented in a runtime support library Prosâ€¢ Thread management and switching at user level is much faster than doing it in kernel level â€¢ No need to trap (take syscall exception) into kernel and back to switch â€¢ Dispatcher algorithm can be tuned to the application â€¢ E.g. use priorities â€¢ Can be implemented on any OS (thread or non-thread aware) â€¢ Can easily support massive numbers of threads on a per-application basis â€¢ Use normal application virtual memory â€¢ Kernel memory more constrained. Difficult to efficiently support wildly differing numbers of threads for different applications Consâ€¢ Threads have to yield() manually (no timer interrupt delivery to user level) â€¢ Co-operative multithreading â€¢ A single poorly design&#x2F;implemented thread can monopolise the available CPU time â€¢ There are work-arounds (e.g. a timer signal per second to enable pre-emptive multithreading), they are course grain and a kludge. â€¢ Does not take advantage of multiple CPUs (in reality, we still have a single threaded process as far as the kernel is concerned) â€¢ If a thread makes a blocking system call (or takes a page fault), the process (and all the internal threads) blocks â€¢ Canâ€™t overlap I&#x2F;O with computation Kernel-provided Threads Threads are implemented by the kernel â€¢ TCBs (thread control block) are stored in the kernel â€¢ A subset of information in a traditional PCB (process control block) â€¢ The subset related to execution context â€¢ TCBs have a PCB associated with them â€¢ Resources associated with the group of threads (the process) â€¢ Thread management calls are implemented as system calls â€¢ E.g. create, wait, exit Consâ€¢ Thread creation and destruction, and blocking and unblocking threads requires kernel entry and exit. â€¢ More expensive than user-level equivalent Prosâ€¢ Preemptive multithreading â€¢ Parallelism â€¢ Can overlap blocking I&#x2F;O with computation â€¢ Can take advantage of a multiprocessor Context SwitchContext Switch is what the lowest level of OS does when an interrupt occurs. A context switch can refer to â€¢ A switch between threads â€¢ Involving saving and restoring of state associated with a thread â€¢ A switch between processes â€¢ Involving the above, plus extra state associated with a process. â€¢ E.g. memory maps Context Switch OccurrenceA switch between process&#x2F;threads can happen any time the OS is invoked â€¢ On a system call â€¢ Mandatory if system call blocks or on exit(); â€¢ On an exception â€¢ Mandatory if offender is killed â€¢ On an interrupt â€¢ Triggering a dispatch is the main purpose of the timer interrupt A thread switch can happen between any two instructions Note instructions do not equal program statements Context Switch Addition Context switch must be transparent for processes&#x2F;threads â€¢ When dispatched again, process&#x2F;thread should not notice that something else was running in the meantime (except for elapsed time) OS must save all state that affects the thread â€¢ This state is called the process&#x2F;thread context â€¢ Switching between process&#x2F;threads consequently results in a context switch. Lec06 SyscallsSyscall DefinitionCan be viewed as special function calls â€¢ Provides for a controlled entry into the kernel â€¢ While in kernel, they perform a privileged operation â€¢ Returns to original caller with the result The system call interface represents the abstract machine provided by the operating system. CPU Computation ModelThe fetch-execute cycle â€¢ Load memory contents from address in program counter (PC) â€¢ The instruction â€¢ Execute the instruction â€¢ Increment PC â€¢ Repeat Privileged-mode operationTo protect operating system execution, two or more CPU modes of operation exist â€¢ Privileged mode (system-, kernel-mode) â€¢ All instructions and registers are available â€¢ User-mode â€¢ Uses â€˜safeâ€™ subset of the instruction set â€¢ Only affects the state of the application itself â€¢ They cannot be used to uncontrollably interfere with OS â€¢ Only â€˜safeâ€™ registers are accessible The accessibility of addresses within an address space changes depending on operating mode â€¢ To protect kernel code and data â€¢ Note: The exact memory ranges are usually configurable, and vary between CPU architectures and&#x2F;or operating systems. System call mechanism securely transfers from user execution to kernel execution and back. System call mechanism overviewâ€¢ Processor mode â€¢ Switched from user-mode to kernel-mode â€¢ Switched back when returning to user mode â€¢ Stack Pointer (SP) â€¢ User-level SP is saved and a kernel SP is initialised â€¢ User-level SP restored when returning to user-mode â€¢ Program Counter (PC) â€¢ User-level PC is saved and PC set to kernel entry point â€¢ User-level PC restored when returning to user-level â€¢ Kernel entry via the designated entry point must be strictly enforced â€¢Registers â€¢ Set at user-level to indicate system call type and its arguments â€¢ A convention between applications and the kernel â€¢ Some registers are preserved at user-level or kernel-level in order to restart user-level execution â€¢ Depends on language calling convention etc. â€¢ Result of system call placed in registers when returning to user-level â€¢ Another convention We need system calls because function calls do not: Change from user to kernel mode&#x2F;back again Restrict possible entry points to secure locations Coprocessor 0 (CP0)The processor control registers are located in CP0 Exception&#x2F;Interrupt management registers Translation management registers Exception management C0_statusWe only focus on 0-15 bits Â·c0_causeThe 2nd-6th bit is for ExcCode -&gt; The code number of the exception taken C0_epcThe Exception Program Counter â€¢ Points to address of where to restart execution after handling the exception or interrupt Hardware Exception handlingBasic situation: Assume an interrupt occurred as the previous instruction completed &amp; We are in user mode with interrupts enabled. Steps: Instruction address at which to restart after the interrupt is transferred to EPC Interrupts disabled and previous state shifted along What stored in IEc&#x2F;KUc is now in IEp&#x2F;KUp Kernel mode is set, and previous state shifted along What stored in IEp&#x2F;KUp (before 2 a) executed) is now in IEo&#x2F;KUo Code for the exception placed in Cause -&gt; ExcCode in c0_cause is now 0 (0 is the code for interrupt) Address of general exception vector placed in PC CPU now running in kernel mode at the address in PC, with interrupt disabled All information required to Find out what caused the exception Restart after exception handling Is in coprocessor registers (Ignore how the OS handles the exception) Load the contents of EPC Store the EPC back in the PC In the branch delay slot (happens when we jump back to the PC&#x2F;user mode), execute a restore from exception instruction -&gt; move back KU&#x2F;IE Now back in the same state we were when the exception happened MIPS System Callsâ€¢ System calls are invoked via a syscall instruction. â€¢ The syscall instruction causes an exception and transfers control to the general exception handler â€¢ A convention (an agreement between the kernel and applications) is required as to how user-level software indicates â€¢ Which system call is required â€¢ Where its arguments are â€¢ Where the result should go OS&#x2F;161 Systems CallsOS&#x2F;161 uses the following conventions: â€¢ Arguments are passed and returned via the normal C function calling convention â€¢ Additionally â€¢ Reg v0 contains the system call number â€¢ On return, reg a3 contains â€¢ 0: if success, v0 contains successful result â€¢ not 0: if failure, v0 has the errno. â€¢ v0 stored in errno â€¢ -1 returned in v0 Summary of System Call in User Modeâ€¢ From the callerâ€™s perspective, the read() system call behaves like a normal function call â€¢ It preserves the calling convention of the language â€¢However, the actual function implements its own convention by agreement with the kernel â€¢ Our OS&#x2F;161 example assumes the kernel preserves appropriate registers(s0-s8, sp, gp, ra). â€¢Most languages have similar libraries that interface with the operating system. System Calls â€“ Kernel Sideâ€¢ Things left to do â€¢ Change to kernel stack â€¢ Preserve registers by saving to memory (on the kernel stack) â€¢ Leave saved registers somewhere accessible to â€¢ Read arguments â€¢ Store return values â€¢ Do the â€œread()â€ â€¢ Restore registers â€¢ Switch back to user stack â€¢ Return to application Lec07 Computer Hardware ReviewMemory Hierarchy Cashingâ€¢Given two-levels of data storage: small and fast, versus large and slow, â€¢ Can speed access to slower storage by using intermediate-speed storage as a cache. CPU cache â€¢ CPU cache is fast memory placed between the CPU and main memory â€¢ 1 to a few cycles access time compared to RAM access time of tens â€“ hundreds of cycles â€¢ Holds recently used data or instructions to save memory accesses. â€¢ Matches slow RAM access time to CPU speed if high hit rate â€¢ Is hardware maintained and (mostly) transparent to software â€¢ Sizes range from few kB to tens of MB. â€¢ Usually a hierarchy of caches (2â€“5 levels), on- and off-chip PerformanceThe performance depends on the hit rate in the first level. Effective Access Time Avoid Waiting for Disk Accessâ€¢ Keep a subset of the diskâ€™s data in main memory OS uses main memory as a cache of disk contents Avoid Waiting for Internet Accessâ€¢ Keep a subset of the Internetâ€™s data on disk Application uses disk as a cache of the internet Lec08 File ManagementFile NamesFile system must provide a convenient naming scheme â€¢ Textual Names â€¢ May have restrictions â€¢ Only certain characters â€¢ E.g. no â€˜&#x2F;â€™ characters â€¢ Limited length â€¢ Only certain format â€¢ E.g DOS, 8 + 3 â€¢ Case (in)sensitive â€¢ Names may obey conventions (.c files for C files) â€¢ Interpreted by tools (e.g. UNIX) â€¢ Interpreted by operating system (e.g. Windows â€œcon:â€) File Structureâ€¢ Sequence of Bytes â€¢ OS considers a file to be unstructured â€¢ Applications can impose their own structure â€¢ Used by UNIX, Windows, most modern OSes P9 lec08 File Typesâ€¢ Regular files â€¢Directories â€¢Device Files â€“May be divided into â€¢Character Devices â€“ stream of bytes â€¢Block Devices â€¢Some systems distinguish between regular file types â€“ASCII text files, binary files File Access Types (Patterns)â€¢Sequential access é¡ºåºè¯»å†™ â€“read all bytes&#x2F;records from the beginning â€“cannot jump around, could rewind or back up â€“convenient when medium was magnetic tape â€¢Random access éšæœºè¯»å†™ â€“bytes&#x2F;records read in any order â€“essential for data base systems â€“read can be â€¦ â€¢move file pointer (seek), then read or â€“lseek(location,â€¦);read(â€¦) â€¢each read specifies the file pointer â€“read(location,â€¦) Typical File Operations Create Delete Open Close Read Write Append Seek Get attributes Set Attribute Rename Criteria for File OrganizationThings to consider when designing file layout â€¢Rapid access â€“Needed when accessing a single record â€“Not needed for batch mode â€¢read from start to finish â€¢Ease of update â€“File on CD-ROM will not be updated, so this is not a concern â€¢Economy of storage â€“Should be minimum redundancy in the data â€“Redundancy can be used to speed access such as an index File Directoriesâ€¢Provide mapping between file names and the files themselves â€¢Contain information about files â€“Attributes â€“Location â€“Ownership â€¢Directory itself is a file owned by the operating system Hierarchical (Tree Structured) Directoryâ€¢Files can be located by following a path from the root, or master, directory down various branches â€“This is the absolute pathname for the file â€¢Can have several files with the same file name as long as they have unique path names(åŒä¸€è·¯å¾„ä¸‹çš„æ–‡ä»¶åä¸å¾—ç›¸ç­‰) Relative and Absolute Pathnamesâ€¢Absolute pathname â€“A path specified from the root of the file system to the file A Relative pathname â€“A pathname specified from the cwd (current working directory) Typical Directory Operations Create Delete Opendir Closedir Readdir Rename Link Unlink Nice Properties of UNIX namingâ€¢Simple, regular format â€“Names referring to different servers, objects, etc., have the same syntax. â€¢Regular tools can be used where specialised tools would be otherwise be needed. â€¢Location independent â€“Objects can be distributed or migrated, and continue with the same names Access RightsIn multiuser system, we need to consider the issue of the access rights. Different kinds of Access Rights: None User may not know the existence of the file User is not allowed to read the directory that includes the file Knowledge User can only determine that the file exists and who its owner is Execution The user can load and execute a program but cannot copy it Reading The user can read the file for any purpose, including copying and execution Appending The user can add data to the file but cannot modify or delete any of the fileâ€™s contents Updating The user can modify, delete, and add to the fileâ€™s data. This includes creating the file, rewriting it, and removing all or part of the data Changing protection User can change access rights granted to other users Deletion User can delete the file Owners Has all rights previously listed May grant rights to others using the following classes of users â€¢Specific user â€¢User groups â€¢All for public files Simultaneous AccessIn multiuser system, we need to consider the issue of the simultaneous access. â€¢Most OSes provide mechanisms for users to manage concurrent access to files â€“Example: flock(), lockf(), system calls â€¢Typically â€“User may lock entire file when it is to be updated â€“User may lock the individual records (i.e. ranges) during the update â€¢Mutual exclusion and deadlock are issues for shared access Lec09 File System InternalsUNIX Storage StackFrom lower to Higher: Hard disk platters: Tracks Sectors Disk controller Hides disk geometry, bad sectors Exposes linear sequence of blocks(diskâ€™s interface) Device driver Hides device-specific protocol Exposes block-device interface Disk scheduler&#x2F;buffer cache -&gt; Optimisations Keep recently accessed disk blocks in memory Schedule disk accesses from multiple processes for performance and fairness File System Hides physical location of data on the disk Exposes: Directory hierarchy ç›®å½•çš„å±‚æ¬¡ç»“æ„ Symbolic file names Random-access files Protrction Virtual File System (VFS) Unified interface to multiple File systems Open File Table (OF table)&#x2F;File Descriptor Table (FD table) Keep track of files opened by user-level processes Matches syscall interface to VFS interface Difference between some FSDifferent physical nature of storage devices â€“ Ext3 is optimised for magnetic disks â€“ JFFS2 is optimised for flash memory devices â€“ ISO9660 is optimised for CDROM Different storage capacities â€“ FAT16 does not support drives &gt;2GB â€“ FAT32 becomes inefficient on drives &gt;32GB â€“ ZFS, Btrfs is designed to scale to multi-TB disk arrays Different CPU and memory requirements â€“ FAT16 is not suitable for modern PCs but is a good fit for many embedded devices Proprietary standards â€“ NTFS may be a nice FS, but its specification is closed Property of hard diskâ€“ Seek time â€¢ ~15ms worst case â€“ Rotational delay â€¢ 8ms worst case for 7200rpm drive â€“ For comparison, disk-to-buffer transfer speed of a modern drive is ~10Âµs per 4K block Conclusion: keep blocks that are likely to be accessed together close to each other Implementing a file systemRequirementsThe FS must map symbolic file names into a collection of block addresses. The FS must keep track of â€“ which blocks belong to which files. â€“ in what order the blocks form the file â€“ which blocks are free for allocation Given a logical region of a file, the FS must track the corresponding block(s) on disk. File Allocation MethodsContiguous Allocationâœ” Easy bookkeeping (need to keep track of the starting block and length of the file) âœ” Increases performance for sequential operations âœ— Need the maximum size for the file at the time of creation âœ— As files are deleted, free space becomes divided into many small chunks (external fragmentation) Example: ISO 9660 (CDROM) Dynamic Allocation Strategiesâ€“ Disk space allocated in portions as needed â€“ Allocation occurs in fixed-size blocks âœ” No external fragmentation âœ” Does not require pre-allocating disk space âœ— Partially filled blocks (internal fragmentation) âœ— File blocks are scattered across the disk âœ— Complex metadata management (maintain the collection of blocks for each file) Examples come after: Linked list allocation File Allocation Table (FAT) Inode-based FS structure External and Internal fragmentationExternal fragmentationâ€“ The space wasted external to the allocated memory regions â€“ Memory space exists to satisfy a request but it is unusable as it is not contiguous Internal fragmentationâ€“ The space wasted internal to the allocated memory regions â€“ Allocated memory may be slightly larger than requested memory; this size difference is wasted memory internal to a partition ConclusionInternal fragmentation is inside the allocated memory blocks External fragmentation is between two allocated memory blocks Dynamic allocation : Linked list allocationEach block contains the block number of the next block in the chain. Free blocks are also linked in a chain. âœ” Only single metadata entry per file âœ” Best for sequentially accessed files âœ— Poor for random access âœ— Blocks end up scattered across the disk due to free list eventually being randomised Dynamic Allocation: File allocation Table (FAT)â€¢ Keep a map of the entire FS in a separate table â€“ A table entry contains the number of the next block of the file â€“ The last block in a file and empty blocks are marked using reserved values â€¢ The table is stored on the disk and is replicated in memory â€¢ Random access is fast (following the in-memory list) Issues: Requires a lot of memory for large disks File allocation table disk layout Dynamical Allocation: inode-based FS structureIdea: separate table (index-node or i-node) for each file. â€“ Only keep table for open files in memory â€“ Fast random access The most popular FS structure today Issues: i-nodes occupy one or several disk areas i-nodes are allocated dynamically, hence free-space management is required for i-nodes â€“ Use fixed-size i-nodes to simplify dynamic allocation â€“ Reserve the last i-node entry for a pointer (a block number) to an extension i-node Free-space management Approach 1: Linked list of free blocks in free blocks on disk Keep bitmaps of free blocks and free i-nodes on disk Free block ListList of all unallocated blocks Background jobs can re-order list for better contiguity Store in free blocks themselves â€“ Does not reduce disk capacity Only one block of pointers need be kept in the main memory Bit tablesIndividual bits in a bit vector flags used&#x2F;free blocks 16GB disk with 512-byte blocks â€“&gt; 4MB table May be too large to hold in main memory Expensive to search â€“ Optimisations possible, e.g. a two level table Concentrating (de)allocations in a portion of the bitmap has desirable effect of concentrating access Simple to find contiguous free space Implementing directoriesâ€¢ Directories are stored like normal files â€“ directory entries are contained inside data blocks â€¢ The FS assigns special meaning to the content of these files â€“ a directory file is a list of directory entries â€“ a directory entry contains file name, attributes, and the file i-node number â€¢ maps human-oriented file name to a system-oriented name Fixed-size directory entriesâ€“ Either too small â€¢ Example: DOS 8+3 characters â€“ Or waste too much space â€¢ Example: 255 characters per file name Variable-size directory entriesâ€“ Freeing variable length entries can create external fragmentation in directory blocks â€¢ Can compact when block is in RAM Searching Directory methods Linear scan Implement a directory cache in software to speed-up search Hash lookup B-tree Storing file attributes Disk addresses and attributes in directory entry -&gt; FAT Directory in which each entry just refers to an i-node -&gt; UNIX File system block sizeFile systems deal with 2 types of blocks â€“ Disk blocks or sectors (usually 512 bytes) â€“ File system blocks 512 * 2^N bytes What should N be will be the problem. â€¢ Smaller blocks waste less disk space (less internal fragmentation) â€¢ Sequential Access â€“ The larger the block size, the fewer I&#x2F;O operations required â€¢ Random Access â€“ The larger the block size, the more unrelated data loaded. â€“ Spatial locality of access improves the situation â€¢ Choosing an appropriate block size is a compromise Lec10 UNIX File Management (continue)Virtual file system (VFS)Traversing the directory hierarchy may require VFS to issue requests to several underlying file systems. â€¢ Provides single system call interface for many file systems â€“ E.g., UFS, Ext2, XFS, DOS, ISO9660,â€¦ â€¢ Transparent handling of network file systems â€“ E.g., NFS, AFS, CODA â€¢ File-based interface to arbitrary device drivers (&#x2F;dev) â€¢ File-based interface to kernel data structures (&#x2F;proc) â€¢ Provides an indirection layer for system calls â€“ File operation table set up at file open time â€“ Points to actual handling code for particular type â€“ Further file operations redirected to those functions Data Types in VFS InterfaceVFS Represent all file system types Contains pointers to functions to manipulate each file system as a whole Form a standard interface to the file system Vnode Represents a file (inode) in the underlying filesystem Points to the real inode Contains pointers to funcions to manipulate files&#x2F;inodes like open&#x2F;close&#x2F;read File descriptorsAttributes Each open file has a file descriptor Read&#x2F;Write&#x2F;Lseek&#x2F;â€¦ use them to specify which file to operate on. State associated with a file descriptor File pointer Determine where in the file the next read or write is performed Mode Was the file opened with read-only permission or sthâ€¦ Use single fd table with no of tableHow to achieve: Use vnode numbers as file descriptors and add a file pointer to the vnode. Problem: Cannot handling concurrency situations. At this situation: we only have a single global open file array. Entries contains file pointer and a pointer to a vnode. Issues: File descriptor 1 is stdout -&gt; console for some processes but may be a file for other processes Entry 1 should be different different per process! Per-process File descriptor array Each process has its own open file array Issue Fork Fork defines that the child shares the file pointer with the parent Dup2 Also defines the file descriptors share the file pointer With per-process table, we can only have independent file pointers, even when accessing the same file Per-Process fd table with global open file table Per-process file descriptor array contains pointers to open file table entry Open file table array contains entries with a file pointer and a pointer to an vnode. This model provides Shared file pointers if required Independent file pointers if required This model used by linux and most other UNIX operating systems Bufferâ€“Temporary storage used when transferring data between two entities â€¢Especially when the entities work at different rates â€¢Or when the unit of transfer is incompatible â€¢Example: between application program and disk Buffer disk blocksâ€¢Allow applications to work with arbitrarily sized region of a file â€“However, apps can still optimise for a particular block size â€¢Writes can return immediately after copying to kernel buffer â€“Avoids waiting until write to disk is complete â€“Write is scheduled in the background â€¢Can implement read-ahead by pre-loading next block on disk into kernel buffer â€“Avoids having to wait until next read is issued CacheFast storage used to temporarily hold data to speed up repeated access to the data -&gt; such as main memory can cache disk blocks â€¢On access â€“Before loading block from disk, check if it is in cache first â€¢Avoids disk accesses â€¢Can optimise for repeated access for single or several processes Buffer and caching are relatedâ€¢Data is read into buffer; an extra independent cache copy would be wasteful â€¢After use, block should be cached â€¢Future access may hit cached copy â€¢Cache utilises unused kernel memory space; â€“may have to shrink, depending on memory demand Cache replacementWhen the buffer cache is full and we need to read another block into memory, we must choose an existing entry to replace Policies: FIFO (first in first out) Least recently used Etc. File system consistencyGenerally, cached disk blocks are prioritised in terms of how critical they are to file system consistency. â€“Directory blocks, inode blocks if lost can corrupt entire filesystem â€¢These blocks are usually scheduled for immediate write to disk â€“Data blocks if lost corrupt only the file that they are associated with â€¢These blocks are only scheduled for write back to disk periodically â€¢In UNIX, flushd (flush daemon) flushes all modified blocks to disk every 30 seconds Possible SolutionWrite-through cache All modified blocks are written immediately to disk But this will generate more disk traffic Works in the following situations: Floppies were removed from drives Users were constantly resetting (or crashing) their machines This method is still be used in USB storage. NOT FINISHED YET"},{"title":"test for categories","date":"2023-03-21T08:13:40.000Z","url":"/2023/03/21/test-for-cat/","tags":[["test","/tags/test/"]],"categories":[["Demo","/categories/Demo/"]],"content":"This is a blog for testing! ä»…ä¾›æµ‹è¯•å·¦ä¸‹è§’æœ‰éŸ³ä¹å“¦ç©å¾—æ„‰å¿« JUST A DEMO! test for alertså–µå‘¼å‘¼å–µå‘¼å‘¼o(&#x3D;â€¢ã‚§â€¢&#x3D;)m æˆåŠŸæˆåŠŸå•¦o(ï¿£â–½ï¿£)ãƒ– å±é™©æœ‰å±é™©Î£(ã£ Â°Ğ” Â°;)ã£ æ¶ˆæ¯æœ‰æ¶ˆæ¯(ãƒ»âˆ€ãƒ»(ãƒ»âˆ€ãƒ»(ãƒ»âˆ€ãƒ»*) å½“å¿ƒå½“å¿ƒå“¦â‰§ ï¹ â‰¦ test for folder è¿™æ˜¯ä¸€ä¸ªå±•å¼€äº†çš„folder ä»€ä¹ˆéƒ½æ²¡æœ‰æ è¿™æ˜¯ä¸€ä¸ªå…³é—­çš„folder è®°å¾—æ‰“å¼€éŸ³ä¹å“¦ï¼ *ä½ ä¸Šå½“äº†æ* test for blurè¿™æ˜¯ä¸€å¥è¢«æ¨¡ç³Šçš„è¯­å¥ test for image insertå°è¯•ç‚¹å‡»ä¸€ä¸‹å§ğŸ‘‡ test for playing youtube æ²¡æƒ³åˆ°å§æ˜¯åŒé‡è¯ˆéª— thats allï¼"},{"title":"hello-world","date":"2023-03-20T06:04:12.000Z","url":"/2023/03/20/hello-world/","categories":[["Demo","/categories/Demo/"]],"content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post More info: Writing Run server More info: Server Generate static files More info: Generating Deploy to remote sites More info: Deployment"}]